{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIPN 145 Fly Tracker\n",
    "\n",
    "This notebook tracks a fruit fly against a light background in a video, calculates its position and velocity over time, and produces path and velocity plots.\n",
    "\n",
    "**Original MATLAB code** by Jeff Stafford, modified by A. Juavinett for BIPN 145.\n",
    "\n",
    "## How to use\n",
    "1. Run the **Setup** cell to install dependencies.\n",
    "2. **Upload your video** (`.avi`, `.mp4`, etc.) using the upload cell.\n",
    "3. **Set your parameters** (dish diameter, frame rate).\n",
    "4. **Draw your ROI** on the first frame.\n",
    "5. Run the remaining cells to track the fly and view results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title Install & import packages { display-mode: \"form\" }\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nfrom matplotlib.collections import LineCollection\nfrom scipy.spatial.distance import euclidean\nfrom google.colab import files, output\nfrom IPython.display import display, clear_output, HTML, Image as IPImage\nimport ipywidgets as widgets\nimport os\nimport base64\n\nprint('All packages loaded successfully!')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Video(s)\n",
    "\n",
    "Upload one or more fly videos. Supported formats: `.avi`, `.mp4`, `.mov`, `.mkv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded = files.upload()\n",
    "video_files = sorted(uploaded.keys())\n",
    "print(f'{len(video_files)} file(s) uploaded: {video_files}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Parameters { run: \"auto\" }\n",
    "\n",
    "# Diameter of the dish in centimeters\n",
    "diameter = 4  #@param {type:\"number\"}\n",
    "\n",
    "# Frame rate of the video (frames per second)\n",
    "frame_rate = 30  #@param {type:\"integer\"}\n",
    "\n",
    "# Search size for fly detection (in pixels) - generally leave at 20\n",
    "search_size = 20  #@param {type:\"integer\"}\n",
    "\n",
    "# Per-pixel intensity threshold - generally leave at 1.5\n",
    "per_pixel_threshold = 1.5  #@param {type:\"number\"}\n",
    "\n",
    "# Bin size for velocity calculation (in seconds)\n",
    "bin_size = 1  #@param {type:\"number\"}\n",
    "\n",
    "height = diameter\n",
    "width = diameter\n",
    "\n",
    "print(f'Dish diameter: {diameter} cm')\n",
    "print(f'Frame rate: {frame_rate} fps')\n",
    "print(f'Search size: {search_size} px')\n",
    "print(f'Velocity bin size: {bin_size} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "These replicate the MATLAB helper functions (`flyFinder`, `distFilter`, `interpolatePos`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title Define helper functions (fly_finder, dist_filter, interpolate_pos) { display-mode: \"form\" }\n\ndef fly_finder(roi_image, half_search, threshold, flip=True):\n    \"\"\"\n    Find a fly (dark region) in a grayscale image.\n    Locates the darkest pixel, retrieves a search area around it,\n    and finds the center of pixel intensity.\n\n    Returns (x, y) position or (NaN, NaN) if not found.\n    \"\"\"\n    if flip:\n        val = np.nanmin(roi_image)\n    else:\n        val = np.nanmax(roi_image)\n\n    ys, xs = np.where(roi_image == val)\n    xpos = np.mean(xs)\n    ypos = np.mean(ys)\n\n    h, w = roi_image.shape\n    left = max(int(round(xpos) - half_search), 0)\n    right = min(int(round(xpos) + half_search), w - 1)\n    top = max(int(round(ypos) - half_search), 0)\n    bottom = min(int(round(ypos) + half_search), h - 1)\n\n    search_area = roi_image[top:bottom+1, left:right+1].astype(np.float64)\n\n    if flip:\n        search_area = 255.0 - search_area\n\n    total = np.sum(search_area)\n\n    if total >= threshold:\n        # Center of mass\n        x_indices = np.arange(search_area.shape[1])\n        y_indices = np.arange(search_area.shape[0])\n        x = np.sum(search_area @ x_indices) / total + left\n        y = np.sum(search_area.T @ y_indices) / total + top\n        return x, y\n    else:\n        return np.nan, np.nan\n\n\ndef dist_filter(array, tele_dist_threshold, num_avg=5):\n    \"\"\"\n    Teleport filter: removes spurious points where fly position\n    jumps far from the mean of surrounding frames.\n\n    array: Nx3 array [time, x, y]\n    \"\"\"\n    filtered = array.copy()\n    tele_count = 0\n\n    for i in range(num_avg, len(filtered) - num_avg):\n        point = filtered[i, 1:3]\n        if np.any(np.isnan(point)):\n            continue\n\n        last_set = filtered[i - num_avg:i, 1:3]\n        last_set = last_set[~np.isnan(last_set[:, 0])]\n        if len(last_set) == 0:\n            continue\n        last_mean = np.mean(last_set, axis=0)\n\n        next_set = filtered[i + 1:i + 1 + num_avg, 1:3]\n        next_set = next_set[~np.isnan(next_set[:, 0])]\n        if len(next_set) == 0:\n            continue\n        next_mean = np.mean(next_set, axis=0)\n\n        if (euclidean(point, last_mean) > tele_dist_threshold or\n                euclidean(point, next_mean) > tele_dist_threshold):\n            filtered[i, 1:3] = np.nan\n            tele_count += 1\n\n    # More stringent check at start and end\n    for idx in list(range(0, min(5, len(filtered) - 1))) + \\\n               list(range(max(0, len(filtered) - 6), len(filtered) - 1)):\n        if np.any(np.isnan(filtered[idx, 1:3])) or np.any(np.isnan(filtered[idx + 1, 1:3])):\n            continue\n        if euclidean(filtered[idx, 1:3], filtered[idx + 1, 1:3]) > tele_dist_threshold / 2:\n            filtered[idx, 1:3] = np.nan\n            tele_count += 1\n\n    print(f'{tele_count} points removed by the teleportation filter.')\n    return filtered\n\n\ndef interpolate_pos(array, inter_dist_threshold):\n    \"\"\"\n    Linearly interpolate fly position between NaN gaps,\n    as long as the gap endpoints are within inter_dist_threshold.\n\n    array: Nx3 array [time, x, y]\n    \"\"\"\n    result = array.copy()\n    interp_count = 0\n\n    col_pairs = [(1, 2)]  # x, y columns\n    for cx, cy in col_pairs:\n        i = 0\n        while i < len(result):\n            if np.isnan(result[i, cx]) and i > 0:\n                last_idx = i - 1\n                last_point = result[last_idx, cx:cy+1]\n                # Find next non-NaN\n                remaining = result[i:, cx]\n                non_nan = np.where(~np.isnan(remaining))[0]\n                if len(non_nan) == 0:\n                    break\n                next_idx = non_nan[0] + i\n                next_point = result[next_idx, cx:cy+1]\n                gap = next_idx - i\n\n                if euclidean(last_point, next_point) <= inter_dist_threshold:\n                    for j in range(1, gap + 1):\n                        frac = j / (gap + 1)\n                        result[last_idx + j, cx:cy+1] = last_point + (next_point - last_point) * frac\n                    interp_count += gap\n\n                i = next_idx\n            elif np.isnan(result[i, cx]) and i == 0:\n                non_nan = np.where(~np.isnan(result[:, cx]))[0]\n                if len(non_nan) == 0:\n                    break\n                i = non_nan[0]\n            else:\n                i += 1\n\n    print(f'{interp_count} points recovered through interpolation.')\n    return result\n\n\nprint('Helper functions defined.')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Select ROI (Region of Interest)\n\nRun the cell below to display the first frame of your video. **Click and drag** directly on the image to draw a red rectangle around the dish. You can redraw as many times as you like. When you're happy with the ROI, click **Confirm ROI**."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title Interactive ROI selector — click and drag on the image { display-mode: \"form\" }\n\n# Read first frame and encode as base64 for display\ncap = cv2.VideoCapture(video_files[0])\nret, frame = cap.read()\ncap.release()\nif not ret:\n    raise ValueError(f'Could not read first frame of {video_files[0]}')\n\nframe_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\nimg_h, img_w = frame_rgb.shape[:2]\n\n# Encode frame as PNG base64\n_, buf = cv2.imencode('.png', cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR))\nimg_b64 = base64.b64encode(buf).decode('utf-8')\n\nprint(f'Image size: {img_w} x {img_h} pixels')\nprint('Click and drag on the image below to select the ROI, then click \"Confirm ROI\".\\n')\n\n# JavaScript/HTML interactive ROI selector\nhtml_code = f\"\"\"\n<div id=\"roi-container\" style=\"position:relative; display:inline-block; cursor:crosshair;\">\n  <canvas id=\"roi-canvas\" width=\"{img_w}\" height=\"{img_h}\"\n    style=\"max-width:100%; height:auto; border:1px solid #ccc;\"></canvas>\n</div>\n<br>\n<button id=\"roi-confirm-btn\" style=\"font-size:16px; padding:8px 20px; background:#4CAF50;\n  color:white; border:none; border-radius:4px; cursor:pointer; margin-top:8px;\">\n  Confirm ROI\n</button>\n<p id=\"roi-info\" style=\"font-size:14px; color:#333;\"></p>\n\n<script>\n(function() {{\n  var canvas = document.getElementById('roi-canvas');\n  var ctx = canvas.getContext('2d');\n  var img = new window.Image();\n  img.src = 'data:image/png;base64,{img_b64}';\n\n  var drawing = false;\n  var x0 = 0, y0 = 0, x1 = 0, y1 = 0;\n  var hasROI = false;\n\n  // Scale factor: canvas CSS size vs actual pixel size\n  function getScale() {{\n    var rect = canvas.getBoundingClientRect();\n    return {{ sx: canvas.width / rect.width, sy: canvas.height / rect.height }};\n  }}\n\n  img.onload = function() {{\n    ctx.drawImage(img, 0, 0);\n  }};\n\n  function redraw() {{\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n    ctx.drawImage(img, 0, 0);\n    if (hasROI) {{\n      var rx = Math.min(x0, x1);\n      var ry = Math.min(y0, y1);\n      var rw = Math.abs(x1 - x0);\n      var rh = Math.abs(y1 - y0);\n      ctx.strokeStyle = 'red';\n      ctx.lineWidth = 3;\n      ctx.strokeRect(rx, ry, rw, rh);\n      document.getElementById('roi-info').innerText =\n        'ROI: x=' + Math.round(rx) + ', y=' + Math.round(ry) +\n        ', w=' + Math.round(rw) + ', h=' + Math.round(rh);\n    }}\n  }}\n\n  canvas.addEventListener('mousedown', function(e) {{\n    var rect = canvas.getBoundingClientRect();\n    var scale = getScale();\n    x0 = (e.clientX - rect.left) * scale.sx;\n    y0 = (e.clientY - rect.top) * scale.sy;\n    drawing = true;\n    hasROI = false;\n  }});\n\n  canvas.addEventListener('mousemove', function(e) {{\n    if (!drawing) return;\n    var rect = canvas.getBoundingClientRect();\n    var scale = getScale();\n    x1 = (e.clientX - rect.left) * scale.sx;\n    y1 = (e.clientY - rect.top) * scale.sy;\n    hasROI = true;\n    redraw();\n  }});\n\n  canvas.addEventListener('mouseup', function(e) {{\n    drawing = false;\n  }});\n\n  document.getElementById('roi-confirm-btn').addEventListener('click', function() {{\n    if (!hasROI) {{\n      document.getElementById('roi-info').innerText =\n        'No ROI drawn yet! Click and drag on the image first.';\n      return;\n    }}\n    var rx = Math.round(Math.min(x0, x1));\n    var ry = Math.round(Math.min(y0, y1));\n    var rw = Math.round(Math.abs(x1 - x0));\n    var rh = Math.round(Math.abs(y1 - y0));\n\n    // Send ROI back to Python via Colab's kernel eval\n    google.colab.kernel.invokeFunction('set_roi', [rx, ry, rw, rh], {{}});\n    document.getElementById('roi-info').innerText =\n      'ROI CONFIRMED: x=' + rx + ', y=' + ry + ', w=' + rw + ', h=' + rh;\n    document.getElementById('roi-confirm-btn').style.background = '#888';\n    document.getElementById('roi-confirm-btn').innerText = 'ROI Confirmed!';\n  }});\n}})();\n</script>\n\"\"\"\n\n# Register a callback so JavaScript can send the ROI to Python\nroi_result = {'value': None}\n\ndef set_roi(x, y, w, h):\n    roi_result['value'] = (int(x), int(y), int(w), int(h))\n    print(f'ROI received: x={int(x)}, y={int(y)}, w={int(w)}, h={int(h)}')\n\noutput.register_callback('set_roi', set_roi)\n\ndisplay(HTML(html_code))"
  },
  {
   "cell_type": "code",
   "source": "# Run this cell AFTER you have confirmed your ROI above\nroi = roi_result['value']\n\nif roi is None:\n    raise ValueError(\"No ROI selected! Go back and draw a rectangle on the image, then click 'Confirm ROI'.\")\n\nprint(f'Using ROI: x={roi[0]}, y={roi[1]}, width={roi[2]}, height={roi[3]}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track Fly in Video(s)\n",
    "\n",
    "This processes each video frame-by-frame:\n",
    "1. Creates a background image from 100 random frames\n",
    "2. Subtracts the background from each frame\n",
    "3. Finds the fly position using center-of-mass of dark pixels\n",
    "4. Applies teleportation filter and interpolation\n",
    "5. Converts pixel positions to centimeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title Fly tracking engine — process_video() { display-mode: \"form\" }\n\ndef process_video(video_path, roi, diameter, frame_rate, search_size, per_pixel_threshold):\n    \"\"\"\n    Process a single fly video and return the corrected position array.\n\n    Returns:\n        corrected_array: Nx3 array [time_s, x_cm, y_cm]\n        fps: actual frame rate from the video\n    \"\"\"\n    height = diameter\n    width = diameter\n    roi_x, roi_y, roi_w, roi_h = roi\n\n    cap = cv2.VideoCapture(video_path)\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    nfrm = total_frames - 1\n\n    print(f'\\nProcessing: {os.path.basename(video_path)}')\n    print(f'  Video FPS: {fps}, Total frames: {total_frames}')\n    print(f'  Using frame_rate parameter: {frame_rate} for time conversion')\n\n    # --- Create background from 100 random frames ---\n    print('  Calculating background...')\n    bg_number = min(100, nfrm)\n    bg_indices = sorted(np.random.choice(nfrm, bg_number, replace=False))\n\n    # Read first frame to get dimensions\n    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n    ret, sample = cap.read()\n    gray_sample = cv2.cvtColor(sample, cv2.COLOR_BGR2GRAY)\n    bg_array = np.zeros((*gray_sample.shape, bg_number), dtype=np.uint8)\n\n    for idx, frame_num in enumerate(bg_indices):\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n        ret, frame = cap.read()\n        if ret:\n            bg_array[:, :, idx] = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    background = np.mean(bg_array, axis=2).astype(np.uint8)\n\n    # --- Process each frame ---\n    print('  Tracking fly positions...')\n    threshold = (search_size ** 2) * per_pixel_threshold\n    half_search = round(search_size / 2)\n\n    pos_array = np.zeros((nfrm, 3))\n\n    for nofr in range(nfrm):\n        cap.set(cv2.CAP_PROP_POS_FRAMES, nofr)\n        ret, frame = cap.read()\n        if not ret:\n            pos_array[nofr] = [nofr, np.nan, np.nan]\n            continue\n\n        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).astype(np.float64)\n\n        # Background subtraction using GIMP division formula\n        frame_div = np.clip((256.0 * frame_gray) / (background.astype(np.float64) + 1), 0, 255).astype(np.uint8)\n\n        # Crop to ROI\n        frame_crop = frame_div[roi_y:roi_y + roi_h, roi_x:roi_x + roi_w]\n\n        # Find fly\n        fx, fy = fly_finder(frame_crop, half_search, threshold, flip=True)\n        pos_array[nofr] = [nofr, fx, fy]\n\n        # Progress update every 10%\n        if (nofr + 1) % max(1, nfrm // 10) == 0:\n            pct = (nofr + 1) / nfrm * 100\n            print(f'    {pct:.0f}% complete ({nofr + 1}/{nfrm} frames)')\n\n    cap.release()\n\n    # --- Convert to real coordinates ---\n    xscale = width / roi_w\n    yscale = height / roi_h\n\n    corrected_array = np.column_stack([\n        pos_array[:, 0] / frame_rate,  # time in seconds\n        pos_array[:, 1] * xscale,       # x in cm\n        pos_array[:, 2] * yscale        # y in cm\n    ])\n\n    skipped = np.sum(np.isnan(corrected_array[:, 1]))\n    print(f'  {skipped} points skipped out of {nfrm}.')\n\n    # Apply teleport filter and interpolation\n    corrected_array = dist_filter(corrected_array, 2)\n    corrected_array = interpolate_pos(corrected_array, 2)\n\n    # Manual fix for 15fps videos (matching MATLAB behavior)\n    if frame_rate == 15:\n        corrected_array[:, 0] = corrected_array[:, 0] / 4\n\n    return corrected_array\n\n\n# --- Process all uploaded videos ---\nall_corrected = []\nfor vf in video_files:\n    corrected = process_video(vf, roi, diameter, frame_rate,\n                              search_size, per_pixel_threshold)\n    all_corrected.append(corrected)\n\nprint(f'\\nDone! Processed {len(all_corrected)} video(s).')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Fly Path(s)\n",
    "\n",
    "Color-coded by time (blue = start, red = end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "for idx, corrected in enumerate(all_corrected):\n    x = corrected[:, 1]\n    y = corrected[:, 2]\n    t = corrected[:, 0]\n\n    fig, ax = plt.subplots(figsize=(6, 6))\n\n    # Plot path colored by time\n    valid = ~np.isnan(x) & ~np.isnan(y)\n    points = np.array([x[valid], y[valid]]).T.reshape(-1, 1, 2)\n    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n\n    lc = LineCollection(segments, cmap='viridis', linewidth=2)\n    lc.set_array(t[valid][:-1])\n    ax.add_collection(lc)\n\n    ax.set_xlim(0, width)\n    ax.set_ylim(height, 0)  # Invert y to match video\n    ax.set_aspect('equal')\n    ax.set_xlabel('X-coordinate (cm)', fontsize=11)\n    ax.set_ylabel('Y-coordinate (cm)', fontsize=11)\n    ax.set_title(f'Fly Path — {video_files[idx]}')\n\n    cbar = fig.colorbar(lc, ax=ax, orientation='horizontal', pad=0.1)\n    cbar.set_label('Time (s)')\n\n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate & Plot Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_velocity = []\n",
    "\n",
    "for idx, corrected in enumerate(all_corrected):\n",
    "    x = corrected[:, 1]\n",
    "    y = corrected[:, 2]\n",
    "\n",
    "    total_time = len(x) / frame_rate\n",
    "    total_bins = int(np.floor(total_time / bin_size))\n",
    "\n",
    "    # Calculate velocity per bin\n",
    "    data_rate = round(1.0 / corrected[1, 0]) * bin_size if corrected[1, 0] > 0 else frame_rate * bin_size\n",
    "    data_rate = int(data_rate)\n",
    "\n",
    "    if data_rate < 1:\n",
    "        raise ValueError('bin_size is smaller than the minimum data rate.')\n",
    "\n",
    "    velocity = np.zeros(total_bins)\n",
    "    for row in range(0, len(corrected) - data_rate, data_rate):\n",
    "        bin_idx = row // data_rate\n",
    "        if bin_idx >= total_bins:\n",
    "            break\n",
    "        p1 = corrected[row, 1:3]\n",
    "        p2 = corrected[row + data_rate, 1:3]\n",
    "        if np.any(np.isnan(p1)) or np.any(np.isnan(p2)):\n",
    "            velocity[bin_idx] = np.nan\n",
    "        else:\n",
    "            # 10x converts cm to mm\n",
    "            velocity[bin_idx] = 10.0 * euclidean(p1, p2)\n",
    "\n",
    "    # Convert from mm/bin to mm/s\n",
    "    velocity = velocity / bin_size\n",
    "\n",
    "    all_velocity.append(velocity)\n",
    "\n",
    "    # Warn about absurd velocities\n",
    "    if np.nanmax(velocity) > 30:\n",
    "        print(f'WARNING ({video_files[idx]}): Absurdly high velocities detected.')\n",
    "        print('  Consider changing the ROI or re-recording the video.')\n",
    "\n",
    "    mean_vel = np.nanmean(velocity)\n",
    "    std_vel = np.nanstd(velocity)\n",
    "    print(f'\\n--- {video_files[idx]} ---')\n",
    "    print(f'  Mean velocity: {mean_vel:.2f} mm/s')\n",
    "    print(f'  Std deviation: {std_vel:.2f} mm/s')\n",
    "\n",
    "    # Plot velocity over time\n",
    "    time_axis = np.arange(total_bins) * bin_size\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.plot(time_axis, velocity, linewidth=1.5)\n",
    "    ax.set_xlim(0, time_axis[-1] + bin_size if len(time_axis) > 0 else 1)\n",
    "    ax.set_ylim(0, np.nanmax(velocity) * 1.5 if np.nanmax(velocity) > 0 else 1)\n",
    "    ax.set_xlabel('Time (s)', fontsize=11)\n",
    "    ax.set_ylabel('Velocity (mm/s)', fontsize=11)\n",
    "    ax.set_title(f'Fly Velocity — {video_files[idx]}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Across All Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_files = len(all_velocity)\n",
    "\n",
    "if num_files > 1:\n",
    "    # Pad velocity arrays to the same length for comparison\n",
    "    max_len = max(len(v) for v in all_velocity)\n",
    "    velocity_matrix = np.full((num_files, max_len), np.nan)\n",
    "    for i, v in enumerate(all_velocity):\n",
    "        velocity_matrix[i, :len(v)] = v\n",
    "\n",
    "    # Plot all velocities together\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    time_axis = np.arange(max_len) * bin_size\n",
    "    for i in range(num_files):\n",
    "        ax.plot(time_axis, velocity_matrix[i], linewidth=2,\n",
    "                label=f'Fly {i + 1}')\n",
    "    ax.set_xlabel('Time (s)', fontsize=11)\n",
    "    ax.set_ylabel('Velocity (mm/s)', fontsize=11)\n",
    "    ax.set_title('All Fly Velocities')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Summary stats across videos\n",
    "    per_video_means = [np.nanmean(v) for v in all_velocity]\n",
    "    mean_across = np.mean(per_video_means)\n",
    "    sd_across = np.std(per_video_means)\n",
    "    print(f'\\n=== Summary Across {num_files} Videos ===')\n",
    "    print(f'Mean velocity across videos: {mean_across:.2f} mm/s')\n",
    "    print(f'SD of mean velocity across videos: {sd_across:.2f} mm/s')\n",
    "else:\n",
    "    mean_vel = np.nanmean(all_velocity[0])\n",
    "    sd_vel = np.nanstd(all_velocity[0])\n",
    "    print(f'\\n=== Summary (1 Video) ===')\n",
    "    print(f'Mean velocity: {mean_vel:.2f} mm/s')\n",
    "    print(f'SD of velocity: {sd_vel:.2f} mm/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Results (Optional)\n",
    "\n",
    "Download the tracking data as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Download tracking data? { run: \"auto\" }\n",
    "download_data = True  #@param {type:\"boolean\"}\n",
    "\n",
    "if download_data:\n",
    "    for idx, corrected in enumerate(all_corrected):\n",
    "        base = os.path.splitext(video_files[idx])[0]\n",
    "        csv_name = f'{base}_tracking.csv'\n",
    "        np.savetxt(csv_name, corrected, delimiter=',',\n",
    "                   header='Time_s,X_cm,Y_cm', comments='')\n",
    "        files.download(csv_name)\n",
    "        print(f'Downloaded {csv_name}')\n",
    "\n",
    "    # Also save velocity data\n",
    "    for idx, vel in enumerate(all_velocity):\n",
    "        base = os.path.splitext(video_files[idx])[0]\n",
    "        csv_name = f'{base}_velocity.csv'\n",
    "        time_axis = np.arange(len(vel)) * bin_size\n",
    "        vel_data = np.column_stack([time_axis, vel])\n",
    "        np.savetxt(csv_name, vel_data, delimiter=',',\n",
    "                   header='Time_s,Velocity_mm_per_s', comments='')\n",
    "        files.download(csv_name)\n",
    "        print(f'Downloaded {csv_name}')"
   ]
  }
 ]
}